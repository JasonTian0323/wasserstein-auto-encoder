#fig5

It is important to note, for the purpose of this comparison that the WAE has a free parameter $\lambda$ not considered in the VAE.

For a fair comparison of the VAE we would recommend adding a $\lambda$ parameter to the KLD term of the VAE.
Alternate formulations on the

In the plots below we provide visualizations showing a series pixel space representations of the MNIST dataset compared to decoded representations from each of our auto-encoder implementations, AE, VAE, and WAE, each as a separate row of images in that order. These plots provide a means to visually inspect how each auto-encoder performed coding and decoding our images. These images also begin to provide us a sense for each auto-encoder's 20-dimensional latent space $Z$ through its decoded "interpretation" of regions not mapped directly to one of its learned sample images.

For instance, in [Figure 6](#fig6) below we can see that some of the abnormal details for digits in the first row (most notably the jagged shaped at the top of zero on the far left and the stray mark beside the second one shown in that row) are captured and rendered in the encoding/decodings provided by the AE as well as the WAE, but notably not by the VAE. While all three auto-encoders appear to do a good job of reconstructing our input images, it is this added level of detail and accuracy that we would expect for both the AE and WAE as was evidenced by the lower test reconstruction error for both of these models in contrast to the VAE.

Next, in [Figure 7](#fig7) we draw random samples $Normal(0,1)$ from our latent spaces for each auto-encoder to better explore that space. In this example, we provide as reference in row 1 the noisy representation that such sampling provides when drawn from pixel space of our original MNIST training images.  This is then compared, row-by-row, to the decoded representations for the AE, VAE, and WAE. Here we would expect less "noise" in our VAE and WAE representations leading to representations better resembling actual digits than the AE. We would expect this primarily because of the basic AE's lack of a probabilistic latent distribution, meaning that the AE is not "learning" this dataset's latent space in the same manner that it is being learned by the VAE or WAE. While the AE's results in Figure 7 do appear to be less discernible or noisier than those of the VAE and WAE, it is not until the results plotted further below in this tutorial against that FashionMNIST dataset ([Figure 10](#fig10)) that we see a more notable difference between each auto-encoder model when randomly sampled from the latent space.

As a final comparison with MNIST, we look at the linear interpolations between each digit selected from the training set Figure 6. Thus, Figure 8 shows nine equally spaced interpolations between each digit. The first row for each plot of images shows the transition in pixel space, where it is notable that the starting digit slowly fades out as the next digit fades into its place. This is contrasted with the latent space interpolations for each set of digits. For the AE, VAE, and WAE we can see the morphology of these digits, one onto the next, as we transverse the latent space between each digit. Here we can see that each type of auto-encoder has represented this space slightly differently.
