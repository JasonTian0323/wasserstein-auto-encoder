{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to the Wasserstein Auto-encoder\n",
    "\n",
    "-------\n",
    "\n",
    "## Authors\n",
    "Joel Dapello<br>\n",
    "Michael Sedelmeyer<br>\n",
    "Wenjun Yan\n",
    "\n",
    "-------\n",
    "\n",
    "<a id=\"top\"></a>\n",
    "## Contents\n",
    "\n",
    "Table of contents with markdown hyperlinks to each section of the notebook\n",
    "\n",
    "1. [Motivation and background](#intro)\n",
    "\n",
    "1. [Conceptual foundations](#concepts)\n",
    "\n",
    "1. [Mathematics and algorithms](#details)\n",
    "\n",
    "1. [Comparing results on MNIST](#mnist)\n",
    "\n",
    "1. [Comparing results on FashionMNIST](#fmnist)\n",
    "\n",
    "1. [Conclusions and further analysis](#conclusion)\n",
    "\n",
    "1. [References and further reading](#sources)\n",
    "\n",
    "\n",
    "- [Appendices: PyTorch Implementation](#appendix)\n",
    "    - [Appendix A: Auto-encoder](#ae)\n",
    "    - [Appendix B: Variational auto-encoder](#vae)\n",
    "    - [Appendix C: Wasserstein auto-encoder](#wae)\n",
    "    - [Appendix C: Plotting functions](#plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "## Motivation and background\n",
    "[return to top](#top)\n",
    "\n",
    "Introduced in 2018 with the conference paper \"Wasserstein Auto-Encoders\", the authors Tolsikhin, Bousquet, Gelly, and Sch&ouml;lkopf propose the Wasserstein auto-encoder (WAE) as a new algorithm for building a latent-variable-based generative model. Thus, WAE can be thought of as a new addition to the family of regularized auto-encoders, which also includes the the well-known variational auto-encoder (VAE) (Kingma & Welling, 2014). However, unlike the VAE, which focuses on maximizing the evidence lower bound between the model and target distribution, the WAE aims to minimize the optimal transport cost (i.e. the Wasserstein distance between the model distribution and target distribution). This can be thought of intuitively as the cost to transform one distribution into another, leading to a different regularizer than that of the VAE. The WAE regularizer therefore encourages the full encoded training distribution to match a prior rather than individual samples as is done in the case of the VAE (see [Figure 1](#fig1)). For this reason, the WAE shares many of the properties of VAEs, while generating better quality samples due to the continuous mixture induced by the optimal transport penalty.\n",
    "\n",
    "In this tutorial, we provide a general review of the WAE, as well as a direct comparison to the VAE and basic auto-encoder (CITE) (the general non-stochastic variant which we will abbreviate as AE) algorithms. We choose this approach because, to better understand the WAE and its benefits, it is important to consider WAE within the context of these two preceeding and well-established algorithms. An added benefit of this approach is that it also provides a more rich intuitive understanding of the results shown in this tutorial when we demostrate side-by-side comparisons of each algorithm applied to the popular MNIST (CITE) and FashionMNIST (CITE) datasets with convolutional nueral network (CNN) implementations in PyTorch. \n",
    "\n",
    "<a id=\"fig1\"></a>\n",
    "**Figure 1:** Comparison of auto-encoder reconstruction methods (after Tolsikhin, et.al 2018)\n",
    "\n",
    "![alt text](https://github.com/sedelmeyer/wasserstein-auto-encoder/blob/master/images/figure%201%20-%20reconstruction.png?raw=true \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"concepts\"></a>\n",
    "## Conceptual foundations\n",
    "[return to top](#top)\n",
    "\n",
    "To better understand WAE, it is helpful to consider the development of generative auto-encoders beginning with a simple non-stochastic AE, followed by the VAE, and then on to WAE.\n",
    "\n",
    "#### The auto-encoder\n",
    "In its simplest representation, an auto-encoder consists of two networks, an encoder network and a decoder network\n",
    "\n",
    "#### The variational auto-encoder\n",
    "\n",
    "#### The Wasserstein auto-encoder\n",
    "\n",
    "\n",
    "**images to include:**\n",
    "1. simplified CNN diagram demonstrating the generic encoding, latent space bottleneck, and decoding networks as a left-to-right process-flow (similary to either the full-connected or CNN-representative diagram)\n",
    "2. A further simplified version of the CNN diagram, with emphasis on the mechanics of the latent space of each method (i.e. similar to [this sort of image](http://kvfrans.com/content/images/2016/08/vae.jpg), but with MNIST digit images at either end) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"details\"></a>\n",
    "## Mathematics and algorithms\n",
    "[return to top](#top)\n",
    "\n",
    "In this section we provide the mathematical detail and algorithmic differences between each method, paying extra attention to WAE and how it varies from VAE.\n",
    "\n",
    "**latex to include:**\n",
    "1. notational algorithms\n",
    "1. loss function detail\n",
    "1. mathematical representation of the reparameterization trick\n",
    "\n",
    "**images to include:**\n",
    "1. A small graphical representation of the reparameterization trick (small and simple node/edge plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"mnist\"></a>\n",
    "## Comparing results on MNIST\n",
    "[return to top](#top)\n",
    "\n",
    "In this section we specify the parameters used in our model and provide plots and metrics and written interpretation describing the training results and latent space representations of our algorithms on MNIST\n",
    "\n",
    "**images/tables to include:**\n",
    "1. Sample of 5 original MNIST images and corresponding decoded images for AE, VAE, and WAE on separate rows\n",
    "1. Latent space linear interpolation results of each model, pixel space vs AE vs VAE vs WAE on separate rows\n",
    "1. tSNE or PCA representation of pixel space vs latent space for each model to demonstrate differences\n",
    "1. table summarizing comparative loss (and if possible FID results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fmnist\"></a>\n",
    "## Comparing results on FashionMNIST\n",
    "[return to top](#top)\n",
    "\n",
    "Same as above for MNIST\n",
    "\n",
    "**images/tables to include:**\n",
    "1. same as above for MNIST, but probably smaller and with fewer examples if results demonstrate similar characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## Conclusions and further analysis\n",
    "[return to top](#top)\n",
    "\n",
    "Here we summarize our conclusions given MNIST and FMNIST, but also describe other dataset we may want to run as comparison (e.g. celeb faces for representation on a low manifold surface such a faces, RNA expression data for investigation of a novel application of WAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## References and Further Reading\n",
    "[return to top](#top)\n",
    "\n",
    "Cite the papers, repos, datasets, and blogs we used in our analysis, as well as any other resources we want to direct our readers toward\n",
    "\n",
    "1. VAE paper\n",
    "1. WAE paper\n",
    "1. PyTorch/resources implementation of VAE\n",
    "1. AE paper?\n",
    "1. MNIST\n",
    "1. FashionMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"appendix\"></a>\n",
    "## Appendices: PyTorch Implementation\n",
    "[return to top](#top)\n",
    "\n",
    "- The Appendix is where we lay out and run our PyTorch code, each model is separated among sub-appendices\n",
    "- We should output our most important plots to png (saved on GitHub) so we can display them via markdown img link at the appropriate locations in our paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# Set parameter args\n",
    "# load data train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ae\"></a>\n",
    "### Appendix A: Auto-encoder \n",
    "[return to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"vae\"></a>\n",
    "### Appendix B: Variational auto-encoder\n",
    "[return to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"wae\"></a>\n",
    "### Appendix C: Wasserstein auto-encoder\n",
    "[return to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plots\"></a>\n",
    "### Appendix D: Plotting functions\n",
    "[return to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BOTH ALGORITHMS SHOULD PROBABLY BE REWRITTEN USING LATEX IN A WAY THAT TAKES UP LESS VERTICAL SPACE**\n",
    "\n",
    "<a id=\"algo2\"></a>\n",
    "**Algorithm 2:** Wassertein auto-encoder with GAN-based penalty (WAE-GAN) pseudocode\n",
    "\n",
    "**Require:** Regularization coefficient $\\lambda > 0$.\n",
    "\n",
    "> Initialize the parameters fo the encoder $Q_{\\phi}$, decoder $G_{\\theta}$, and latent discriminator $D_{\\gamma}$.\n",
    "\n",
    "> **while** $(\\phi, \\theta)$ not converged **do**\n",
    "\n",
    ">> Sample $\\{x_1, \\dotsc , x_n\\}$ from the training set\n",
    "\n",
    ">> Sample $\\{z_1, \\dotsc , z_n\\}$ from the prior $P_z$\n",
    "\n",
    ">> Sample $\\tilde{z}_i$ from $Q_{\\phi}(Z\\vert x_i)$ for $i=1, \\dotsc , n$\n",
    "\n",
    ">> Update $D_{\\gamma}$ by ascending:\n",
    "$$\\frac{\\lambda}{n}\\sum_{i=1}^n log \\; D_{\\gamma}(z_i) + log (1-D_{\\gamma}(\\tilde{z}_i))$$\n",
    "\n",
    ">> Update $Q_{\\phi}$ and $G_{\\theta}$ by descending:\n",
    "$$\\frac{1}{n}\\sum_{i=1}^n c(x_i, G_{\\theta}(\\tilde{z}_i)) - \\lambda \\cdot log\\;D_{\\gamma}(\\tilde{z}_i)$$\n",
    "> **end while**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"algo1\"></a>\n",
    "**Algorithm 1:** Variational auto-encoder pseudocode for computing a stochastic graient using the estimator\n",
    "\n",
    "**Require:** Regularization coefficient $\\lambda > 0$.\n",
    "\n",
    "> Initialize the parameters for the encoder $Q_{\\phi}$ and decoder $G_{\\theta}$\n",
    "\n",
    "> **while** $(\\phi, \\theta)$ not converged **do**\n",
    "\n",
    ">> Sample $\\{x_1, \\dotsc , x_n\\}$ from the training set\n",
    "\n",
    ">> Sample $\\{\\epsilon_1, \\dotsc , \\epsilon_n\\}$ from the prior $P_z$\n",
    "\n",
    ">> Sample $\\tilde{z}_i$ from $Q_{\\phi}(Z\\vert x_i)$ for $i=1, \\dotsc , n$\n",
    "\n",
    ">> Update $Q_{\\phi}$ and $G_{\\theta}$ by descending:\n",
    "$$\\frac{1}{n}\\sum_{i=1}^n c(x_i, G_{\\theta}(\\tilde{z}_i))$$\n",
    "> **end while**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
